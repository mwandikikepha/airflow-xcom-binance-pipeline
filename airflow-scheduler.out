[2m2025-11-12T12:26:15.253725Z[0m [[32m[1minfo     [0m] [1mStarting the scheduler        [0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:1054[0m
[2m2025-11-12T12:26:15.259284Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
Dag run  in running state
Dag information Queued at: 2025-11-12 12:27:24.418817+00:00 version: 1
[2m2025-11-12T12:27:24.632199Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: binance_etl_dag.extract_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:444[0m
[2m2025-11-12T12:27:24.632480Z[0m [[32m[1minfo     [0m] [1mDAG binance_etl_dag has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:516[0m
[2m2025-11-12T12:27:24.632970Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: binance_etl_dag.extract_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:655[0m
[2m2025-11-12T12:27:24.636285Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: binance_etl_dag.extract_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:740[0m
[2m2025-11-12T12:27:24.840462Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1931[0m
[2m2025-11-12T12:27:28.271471Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m3.541805825996562[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1951[0m [36mtask_instance_id[0m=[35m019a7808-f598-73bb-9b19-7ebf04209036[0m
[2m2025-11-12T12:27:29.199975Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: binance_etl_dag.transform_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:444[0m
[2m2025-11-12T12:27:29.201010Z[0m [[32m[1minfo     [0m] [1mDAG binance_etl_dag has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:516[0m
[2m2025-11-12T12:27:29.201674Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: binance_etl_dag.transform_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:655[0m
[2m2025-11-12T12:27:29.207403Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: binance_etl_dag.transform_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:740[0m
[2m2025-11-12T12:27:29.218946Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='binance_etl_dag', task_id='extract_task', run_id='scheduled__2025-11-12T00:00:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:818[0m
[2m2025-11-12T12:27:29.254546Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=binance_etl_dag, task_id=extract_task, run_id=scheduled__2025-11-12T00:00:00+00:00, map_index=-1, run_start_date=2025-11-12 12:27:24.854214+00:00, run_end_date=2025-11-12 12:27:28.224794+00:00, run_duration=3.37058, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-11-12 12:27:24.633602+00:00, scheduled_dttm=2025-11-12 12:27:24.585810+00:00,queued_by_job_id=7, pid=79483[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:864[0m
[2m2025-11-12T12:27:29.306979Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1931[0m
[2m2025-11-12T12:27:29.749299Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m0.44721876599942334[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1951[0m [36mtask_instance_id[0m=[35m019a7808-f599-7b77-a7cc-9c2730ba7fbf[0m
[2m2025-11-12T12:27:30.456942Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: binance_etl_dag.load_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:444[0m
[2m2025-11-12T12:27:30.457614Z[0m [[32m[1minfo     [0m] [1mDAG binance_etl_dag has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:516[0m
[2m2025-11-12T12:27:30.458310Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: binance_etl_dag.load_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:655[0m
[2m2025-11-12T12:27:30.463228Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: binance_etl_dag.load_task scheduled__2025-11-12T00:00:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:740[0m
[2m2025-11-12T12:27:30.475268Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='binance_etl_dag', task_id='transform_task', run_id='scheduled__2025-11-12T00:00:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:818[0m
[2m2025-11-12T12:27:30.479746Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1931[0m
[2m2025-11-12T12:27:30.497407Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=binance_etl_dag, task_id=transform_task, run_id=scheduled__2025-11-12T00:00:00+00:00, map_index=-1, run_start_date=2025-11-12 12:27:29.319679+00:00, run_end_date=2025-11-12 12:27:29.725262+00:00, run_duration=0.405583, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-11-12 12:27:29.203063+00:00, scheduled_dttm=2025-11-12 12:27:29.135717+00:00,queued_by_job_id=7, pid=79484[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:864[0m
[2m2025-11-12T12:27:30.960457Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m0.4830157300020801[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1951[0m [36mtask_instance_id[0m=[35m019a7808-f59a-735c-b6a9-5fc7036b789f[0m
[2m2025-11-12T12:27:31.837306Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun binance_etl_dag @ 2025-11-12 00:00:00+00:00: scheduled__2025-11-12T00:00:00+00:00, state:running, queued_at: 2025-11-12 12:27:24.418817+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2025-11-12 12:27:24.473221+00:00 end:2025-11-12 12:27:31.837792+00:00
[2m2025-11-12T12:27:31.838681Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=binance_etl_dag, logical_date=2025-11-12 00:00:00+00:00, run_id=scheduled__2025-11-12T00:00:00+00:00, run_start_date=2025-11-12 12:27:24.473221+00:00, run_end_date=2025-11-12 12:27:31.837792+00:00, run_duration=7.364571, state=success, run_type=scheduled, data_interval_start=2025-11-12 00:00:00+00:00, data_interval_end=2025-11-12 00:00:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2025-11-12T12:27:31.986813Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='binance_etl_dag', task_id='load_task', run_id='scheduled__2025-11-12T00:00:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:818[0m
[2m2025-11-12T12:27:31.995017Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=binance_etl_dag, task_id=load_task, run_id=scheduled__2025-11-12T00:00:00+00:00, map_index=-1, run_start_date=2025-11-12 12:27:30.496603+00:00, run_end_date=2025-11-12 12:27:30.899857+00:00, run_duration=0.403254, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-11-12 12:27:30.459778+00:00, scheduled_dttm=2025-11-12 12:27:30.390446+00:00,queued_by_job_id=7, pid=79487[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:864[0m
Dag run  in running state
Dag information Queued at: 2025-11-12 12:27:40.204091+00:00 version: 1
[2m2025-11-12T12:27:41.394842Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: binance_etl_dag.extract_task manual__2025-11-12T12:27:37+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:444[0m
[2m2025-11-12T12:27:41.395024Z[0m [[32m[1minfo     [0m] [1mDAG binance_etl_dag has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:516[0m
[2m2025-11-12T12:27:41.395212Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: binance_etl_dag.extract_task manual__2025-11-12T12:27:37+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:655[0m
[2m2025-11-12T12:27:41.396821Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: binance_etl_dag.extract_task manual__2025-11-12T12:27:37+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:740[0m
[2m2025-11-12T12:27:41.409592Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1931[0m
[2m2025-11-12T12:27:43.332090Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m1.9240699770016363[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1951[0m [36mtask_instance_id[0m=[35m019a7809-3347-7e24-a4b7-5e259643fd42[0m
[2m2025-11-12T12:27:43.688688Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: binance_etl_dag.transform_task manual__2025-11-12T12:27:37+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:444[0m
[2m2025-11-12T12:27:43.688874Z[0m [[32m[1minfo     [0m] [1mDAG binance_etl_dag has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:516[0m
[2m2025-11-12T12:27:43.689089Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: binance_etl_dag.transform_task manual__2025-11-12T12:27:37+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:655[0m
[2m2025-11-12T12:27:43.690723Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: binance_etl_dag.transform_task manual__2025-11-12T12:27:37+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:740[0m
[2m2025-11-12T12:27:43.701130Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='binance_etl_dag', task_id='extract_task', run_id='manual__2025-11-12T12:27:37+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:818[0m
[2m2025-11-12T12:27:43.704140Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1931[0m
[2m2025-11-12T12:27:43.714739Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=binance_etl_dag, task_id=extract_task, run_id=manual__2025-11-12T12:27:37+00:00, map_index=-1, run_start_date=2025-11-12 12:27:41.419836+00:00, run_end_date=2025-11-12 12:27:43.306967+00:00, run_duration=1.887131, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-11-12 12:27:41.395629+00:00, scheduled_dttm=2025-11-12 12:27:41.374046+00:00,queued_by_job_id=7, pid=79490[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:864[0m
[2m2025-11-12T12:27:44.099828Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m0.3976340779918246[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1951[0m [36mtask_instance_id[0m=[35m019a7809-3348-70a2-90c7-bf962340d912[0m
[2m2025-11-12T12:27:44.871898Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: binance_etl_dag.load_task manual__2025-11-12T12:27:37+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:444[0m
[2m2025-11-12T12:27:44.872065Z[0m [[32m[1minfo     [0m] [1mDAG binance_etl_dag has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:516[0m
[2m2025-11-12T12:27:44.872209Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: binance_etl_dag.load_task manual__2025-11-12T12:27:37+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:655[0m
[2m2025-11-12T12:27:44.873850Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: binance_etl_dag.load_task manual__2025-11-12T12:27:37+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:740[0m
[2m2025-11-12T12:27:44.878478Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='binance_etl_dag', task_id='transform_task', run_id='manual__2025-11-12T12:27:37+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:818[0m
[2m2025-11-12T12:27:44.881464Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1931[0m
[2m2025-11-12T12:27:44.891333Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=binance_etl_dag, task_id=transform_task, run_id=manual__2025-11-12T12:27:37+00:00, map_index=-1, run_start_date=2025-11-12 12:27:43.714056+00:00, run_end_date=2025-11-12 12:27:44.069779+00:00, run_duration=0.355723, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-11-12 12:27:43.689557+00:00, scheduled_dttm=2025-11-12 12:27:43.668096+00:00,queued_by_job_id=7, pid=79492[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:864[0m
[2m2025-11-12T12:27:45.332137Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m0.45233231100428384[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1951[0m [36mtask_instance_id[0m=[35m019a7809-3349-7941-9e22-2970522b3b41[0m
[2m2025-11-12T12:27:45.590133Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun binance_etl_dag @ 2025-11-12 12:27:37+00:00: manual__2025-11-12T12:27:37+00:00, state:running, queued_at: 2025-11-12 12:27:40.204091+00:00. run_type: manual> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2025-11-12 12:27:41.323045+00:00 end:2025-11-12 12:27:45.590833+00:00
[2m2025-11-12T12:27:45.591457Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=binance_etl_dag, logical_date=2025-11-12 12:27:37+00:00, run_id=manual__2025-11-12T12:27:37+00:00, run_start_date=2025-11-12 12:27:41.323045+00:00, run_end_date=2025-11-12 12:27:45.590833+00:00, run_duration=4.267788, state=success, run_type=manual, data_interval_start=2025-11-12 12:27:37+00:00, data_interval_end=2025-11-12 12:27:37+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2025-11-12T12:27:45.657338Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='binance_etl_dag', task_id='load_task', run_id='manual__2025-11-12T12:27:37+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:818[0m
[2m2025-11-12T12:27:45.664220Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=binance_etl_dag, task_id=load_task, run_id=manual__2025-11-12T12:27:37+00:00, map_index=-1, run_start_date=2025-11-12 12:27:44.890763+00:00, run_end_date=2025-11-12 12:27:45.258448+00:00, run_duration=0.367685, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-11-12 12:27:44.872641+00:00, scheduled_dttm=2025-11-12 12:27:44.820840+00:00,queued_by_job_id=7, pid=79493[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:864[0m
[2m2025-11-12T12:31:15.481756Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T12:36:15.578586Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T12:41:15.775842Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T12:46:15.821044Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T12:51:15.888397Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T12:56:15.772567Z[0m [[32m[1minfo     [0m] [1mDAG bundles loaded: dags-folder, example_dags[0m [[0m[1m[34mairflow.dag_processing.bundles.manager.DagBundlesManager[0m][0m [36mloc[0m=[35mmanager.py:179[0m
[2m2025-11-12T12:56:15.947308Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T13:01:16.031218Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T13:06:16.120851Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T13:11:16.258310Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
[2m2025-11-12T13:16:16.416868Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2276[0m
